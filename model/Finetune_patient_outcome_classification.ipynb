{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import optim\n",
    "from FinetunePatientClassification import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the preprocessed data for scFoundation\n",
    "data = pd.read_csv('gene_symbol_converted_data_for_scF.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25066, 15093)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract the label data from the original dataset\n",
    "import scanpy as sc\n",
    "anndata = sc.read_h5ad(\"Preprocessed_Data/clono_filtered_counts_adata.h5ad\")\n",
    "anndata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_214234/1035922151.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  anndata.obs['Response_3m'] =  anndata.obs['Response_3m'].replace({'CR':1, 'OR':1, 'NR':0})\n",
      "/tmp/ipykernel_214234/1035922151.py:2: FutureWarning: The behavior of Series.replace (and DataFrame.replace) with CategoricalDtype is deprecated. In a future version, replace will only be used for cases that preserve the categories. To change the categories, use ser.cat.rename_categories instead.\n",
      "  anndata.obs['Response_3m'] =  anndata.obs['Response_3m'].replace({'CR':1, 'OR':1, 'NR':0})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Response_3m\n",
       "1    13160\n",
       "0    11906\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# replace label values with binary values\n",
    "anndata.obs['Response_3m'] =  anndata.obs['Response_3m'].replace({'CR':1, 'OR':1, 'NR':0})\n",
    "anndata.obs['Response_3m'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample the data due to GPU limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "labels_df = anndata.obs\n",
    "patients = labels_df.patient_id.unique()\n",
    "\n",
    "sample_size = 1\n",
    "\n",
    "# randomly sample patient IDs\n",
    "random_seed=42\n",
    "sampled_patient_ids = random.sample(list(patients), sample_size)\n",
    "\n",
    "# Create a new DF with only the sampled patients\n",
    "labels_df_downsampled = labels_df[labels_df['patient_id'].isin(sampled_patient_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the expression data accordingly\n",
    "data_downsampled = data.iloc[labels_df_downsampled.index]\n",
    "\n",
    "# remove the cell_id column\n",
    "data_downsampled = data_downsampled.drop(columns=['cell_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((338, 19264), (338, 7))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the data and labels are aligned\n",
    "data_downsampled.shape, labels_df_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6072</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6073</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6074</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6075</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6076</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>343 rows × 19264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      A1BG  A1CF  A2M  A2ML1  A3GALT2  A4GALT  A4GNT  AAAS  AACS  AADAC  ...  \\\n",
       "6072   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   1.0    0.0  ...   \n",
       "6073   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   1.0    0.0  ...   \n",
       "6074   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "6075   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "6076   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "...    ...   ...  ...    ...      ...     ...    ...   ...   ...    ...  ...   \n",
       "6410   0.0   0.0  0.0    0.0      0.0     0.0    0.0   2.0   0.0    0.0  ...   \n",
       "6411   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "6412   0.0   0.0  0.0    0.0      0.0     0.0    0.0   1.0   0.0    0.0  ...   \n",
       "6413   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "6414   0.0   0.0  0.0    0.0      0.0     0.0    0.0   1.0   0.0    0.0  ...   \n",
       "\n",
       "      ZWILCH  ZWINT  ZXDA  ZXDB  ZXDC  ZYG11A  ZYG11B   ZYX  ZZEF1  ZZZ3  \n",
       "6072     0.0    0.0   0.0   0.0   0.0     0.0     0.0   7.0    1.0   0.0  \n",
       "6073     0.0   13.0   0.0   0.0   0.0     0.0     0.0  11.0    0.0   0.0  \n",
       "6074     0.0    1.0   0.0   0.0   0.0     0.0     0.0   2.0    0.0   0.0  \n",
       "6075     0.0    0.0   0.0   0.0   0.0     0.0     0.0   7.0    0.0   0.0  \n",
       "6076     0.0    1.0   0.0   0.0   0.0     0.0     0.0   1.0    1.0   0.0  \n",
       "...      ...    ...   ...   ...   ...     ...     ...   ...    ...   ...  \n",
       "6410     1.0   15.0   0.0   0.0   0.0     0.0     0.0   2.0    0.0   0.0  \n",
       "6411     1.0    0.0   0.0   0.0   0.0     0.0     0.0   4.0    0.0   0.0  \n",
       "6412     1.0    3.0   0.0   0.0   0.0     0.0     1.0   7.0    1.0   0.0  \n",
       "6413     0.0    0.0   0.0   0.0   0.0     0.0     0.0   1.0    0.0   0.0  \n",
       "6414     0.0    1.0   0.0   0.0   0.0     0.0     0.0   2.0    2.0   0.0  \n",
       "\n",
       "[343 rows x 19264 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCellDataset(Dataset):\n",
    "    def __init__(self, gene_expression_csv, labels_df, label_encoder):\n",
    "        # Load the gene expression data\n",
    "        self.gene_expression = gene_expression_csv\n",
    "        \n",
    "        # Ensure the labels DataFrame has the same number of rows as the gene expression data\n",
    "        assert len(self.gene_expression) == len(labels_df), \"Mismatch in number of samples between gene expression data and labels\"\n",
    "        \n",
    "        # Convert labels to numeric if they're categorical\n",
    "        \n",
    "        self.labels = torch.LongTensor(label_encoder.transform(labels_df['Response_3m']))\n",
    "        \n",
    "        \n",
    "        # Convert gene expression data to torch tensor\n",
    "        self.gene_expression = torch.FloatTensor(self.gene_expression.values.astype(np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x': self.gene_expression[idx],\n",
    "            'targets': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "def print_gpu_memory(step_name):\n",
    "    print(f\"GPU memory at {step_name}: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "def finetune_scFoundation(gene_expression_csv, labels_df, model_class, ckpt_path,\n",
    "                          batch_size=4, num_epochs=5, lr=0.001,\n",
    "                          validation_split=0.2, device='cuda',\n",
    "                          gradient_accumulation_steps=2):\n",
    "    \n",
    "    gene_exp_train, gene_exp_val, labels_train, labels_val = train_test_split(gene_expression_csv, \n",
    "                                                                              labels_df, test_size=validation_split, \n",
    "                                                                              random_state=42)\n",
    "\n",
    "    # Fit LabelEncoder on combined dataset\n",
    "    le = LabelEncoder()\n",
    "    combined_labels = pd.concat([labels_train['Response_3m'], labels_val['Response_3m']])\n",
    "    le.fit(combined_labels)\n",
    "\n",
    "    #create datasets\n",
    "    train_dataset = SingleCellDataset(gene_exp_train, labels_train, le)\n",
    "    val_dataset = SingleCellDataset(gene_exp_val, labels_val, le)\n",
    "\n",
    "    #create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Initialize model\n",
    "    model = model_class(ckpt_path=ckpt_path)\n",
    "    model.build()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Initialize gradient scaler for mixed precision training\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Optionally load checkpoint\n",
    "    start_epoch = 0\n",
    "    \n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "             profile_memory=True, record_shapes=True) as prof:\n",
    "\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            # Clear CUDA cache\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            for i, batch in enumerate(train_loader):\n",
    "                print_gpu_memory(f\"Epoch {epoch}, Batch {i} start\")\n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "                # Mixed precision training\n",
    "                with autocast():\n",
    "                    # Forward pass\n",
    "                    logits = model(batch)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = model.compute_loss(logits, batch['targets'].float()) / gradient_accumulation_steps\n",
    "                \n",
    "                print_gpu_memory(f\"Epoch {epoch}, Batch {i} after forward pass\")\n",
    "                # Ensure loss requires gradient\n",
    "                assert loss.requires_grad, \"Loss does not require gradients\"\n",
    "\n",
    "                # Backward pass with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                print_gpu_memory(f\"Epoch {epoch}, Batch {i} after backward pass\")\n",
    "\n",
    "                if (i + 1) % gradient_accumulation_steps == 0:\n",
    "                    # Unscale gradients and optimizer step\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # add garbage collection\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                    print_gpu_memory(f\"Epoch {epoch}, Batch {i} after optimizer step\")\n",
    "\n",
    "                train_loss += loss.item() * gradient_accumulation_steps\n",
    "            print(f\"Max GPU memory allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "    \n",
    "\n",
    "\n",
    "        #validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        torch.cuda.empty_cache()\n",
    "        print_gpu_memory(f\"Before validation\")\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for j, batch in enumerate(val_loader):\n",
    "                print_gpu_memory(f\"Validation, Batch {j} start\")\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                logits = model(batch)\n",
    "                val_loss += model.compute_loss(logits, batch['targets'].float()).item()\n",
    "                predicted = (torch.sigmoid(logits) > 0.5).float()\n",
    "                total += batch['targets'].size(0)\n",
    "                correct += (predicted == batch['targets']).sum().item()\n",
    "\n",
    "                # Move data back to CPU\n",
    "                for k in batch.keys():\n",
    "                    batch[k] = batch[k].cpu()\n",
    "                del batch, logits, predicted\n",
    "                torch.cuda.empty_cache()\n",
    "\n",
    "                print_gpu_memory(f\"Validation, Batch {j} end\")\n",
    "\n",
    "                \n",
    "        \n",
    "        # Print epoch results\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "        print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "        print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
    "        print(f\"Validation Accuracy: {100*correct/total:.2f}%\")\n",
    "        print(\"-----------------------------\")\n",
    "    \n",
    "    print(prof.key_averages().table(sort_by=\"cuda_memory_total\", row_limit=10))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cell_id</th>\n",
       "      <th>nCount_RNA</th>\n",
       "      <th>nFeature_RNA</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>percent_mito</th>\n",
       "      <th>Response_3m</th>\n",
       "      <th>sample_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Good_Li_2023ac01_AAACGGGAGATGTGTA-1</td>\n",
       "      <td>652</td>\n",
       "      <td>433</td>\n",
       "      <td>ac01</td>\n",
       "      <td>3.935860</td>\n",
       "      <td>1</td>\n",
       "      <td>Deng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good_Li_2023ac01_AAAGATGCAGCCTTGG-1</td>\n",
       "      <td>18106</td>\n",
       "      <td>3790</td>\n",
       "      <td>ac01</td>\n",
       "      <td>2.465065</td>\n",
       "      <td>1</td>\n",
       "      <td>Deng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good_Li_2023ac01_AAAGTAGTCATGGTCA-1</td>\n",
       "      <td>1145</td>\n",
       "      <td>688</td>\n",
       "      <td>ac01</td>\n",
       "      <td>3.858785</td>\n",
       "      <td>1</td>\n",
       "      <td>Deng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Good_Li_2023ac01_AAATGCCAGTACCGGA-1</td>\n",
       "      <td>3430</td>\n",
       "      <td>1413</td>\n",
       "      <td>ac01</td>\n",
       "      <td>2.677339</td>\n",
       "      <td>1</td>\n",
       "      <td>Deng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good_Li_2023ac01_AAATGCCGTTCAGACT-1</td>\n",
       "      <td>924</td>\n",
       "      <td>554</td>\n",
       "      <td>ac01</td>\n",
       "      <td>1.731161</td>\n",
       "      <td>1</td>\n",
       "      <td>Deng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25061</th>\n",
       "      <td>Sheih_TTTGGTTCATTGTGCA-5</td>\n",
       "      <td>2722</td>\n",
       "      <td>1253</td>\n",
       "      <td>NHL-7</td>\n",
       "      <td>6.673766</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25062</th>\n",
       "      <td>Sheih_TTTGGTTTCGATCCCT-5</td>\n",
       "      <td>6209</td>\n",
       "      <td>1980</td>\n",
       "      <td>NHL-7</td>\n",
       "      <td>3.170656</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25063</th>\n",
       "      <td>Sheih_TTTGGTTTCTACGAGT-5</td>\n",
       "      <td>5606</td>\n",
       "      <td>1925</td>\n",
       "      <td>NHL-7</td>\n",
       "      <td>2.868498</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25064</th>\n",
       "      <td>Sheih_TTTGTCACAGTCAGAG-5</td>\n",
       "      <td>2317</td>\n",
       "      <td>1049</td>\n",
       "      <td>NHL-7</td>\n",
       "      <td>2.549102</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheih</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25065</th>\n",
       "      <td>Sheih_TTTGTCATCACCTTAT-5</td>\n",
       "      <td>4198</td>\n",
       "      <td>1580</td>\n",
       "      <td>NHL-7</td>\n",
       "      <td>3.499885</td>\n",
       "      <td>1</td>\n",
       "      <td>Sheih</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25066 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   cell_id  nCount_RNA  nFeature_RNA  \\\n",
       "0      Good_Li_2023ac01_AAACGGGAGATGTGTA-1         652           433   \n",
       "1      Good_Li_2023ac01_AAAGATGCAGCCTTGG-1       18106          3790   \n",
       "2      Good_Li_2023ac01_AAAGTAGTCATGGTCA-1        1145           688   \n",
       "3      Good_Li_2023ac01_AAATGCCAGTACCGGA-1        3430          1413   \n",
       "4      Good_Li_2023ac01_AAATGCCGTTCAGACT-1         924           554   \n",
       "...                                    ...         ...           ...   \n",
       "25061             Sheih_TTTGGTTCATTGTGCA-5        2722          1253   \n",
       "25062             Sheih_TTTGGTTTCGATCCCT-5        6209          1980   \n",
       "25063             Sheih_TTTGGTTTCTACGAGT-5        5606          1925   \n",
       "25064             Sheih_TTTGTCACAGTCAGAG-5        2317          1049   \n",
       "25065             Sheih_TTTGTCATCACCTTAT-5        4198          1580   \n",
       "\n",
       "      patient_id  percent_mito Response_3m sample_source  \n",
       "0           ac01      3.935860           1          Deng  \n",
       "1           ac01      2.465065           1          Deng  \n",
       "2           ac01      3.858785           1          Deng  \n",
       "3           ac01      2.677339           1          Deng  \n",
       "4           ac01      1.731161           1          Deng  \n",
       "...          ...           ...         ...           ...  \n",
       "25061      NHL-7      6.673766           1         Sheih  \n",
       "25062      NHL-7      3.170656           1         Sheih  \n",
       "25063      NHL-7      2.868498           1         Sheih  \n",
       "25064      NHL-7      2.549102           1         Sheih  \n",
       "25065      NHL-7      3.499885           1         Sheih  \n",
       "\n",
       "[25066 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anndata.obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tried downsampling data, batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n",
      "self.encoder.transformer_encoder  0.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  0.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  0.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  0.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  0.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  0.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  0.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  0.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  0.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  1.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  1.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  1.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  1.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  1.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  1.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  1.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  1.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  2.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  2.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  2.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  2.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  2.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  2.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  2.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  2.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  3.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  3.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  3.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  3.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  3.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  3.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  3.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  3.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  4.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  4.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  4.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  4.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  4.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  4.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  4.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  4.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  5.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  5.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  5.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  5.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  5.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  5.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  5.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  5.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  6.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  6.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  6.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  6.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  6.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  6.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  6.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  6.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  7.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  7.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  7.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  7.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  7.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  7.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  7.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  7.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  8.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  8.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  8.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  8.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  8.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  8.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  8.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  8.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  9.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  9.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  9.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  9.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  9.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  9.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  9.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  9.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  10.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  10.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  10.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  10.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  10.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  10.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  10.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  10.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  11.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  11.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  11.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  11.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  11.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  11.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  11.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  11.norm2.bias  no grad\n",
      "self.fc1  0.weight  have grad\n",
      "self.fc1  0.bias  have grad\n",
      "self.fc1  2.weight  have grad\n",
      "self.fc1  2.bias  have grad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-07-24 17:44:33 214234:214234 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory at Epoch 0, Batch 0 start: 0.40 GB\n",
      "GPU memory at Epoch 0, Batch 0 after forward pass: 0.41 GB\n",
      "GPU memory at Epoch 0, Batch 0 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 1 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 1 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 1 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 1 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 2 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 2 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 2 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 3 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 3 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 3 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 3 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 4 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 4 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 4 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 5 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 5 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 5 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 5 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 6 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 6 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 6 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 7 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 7 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 7 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 7 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 8 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 8 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 8 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 9 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 9 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 9 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 9 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 10 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 10 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 10 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 11 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 11 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 11 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 11 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 12 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 12 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 12 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 13 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 13 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 13 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 13 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 14 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 14 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 14 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 15 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 15 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 15 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 15 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 16 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 16 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 16 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 17 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 17 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 17 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 17 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 18 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 18 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 18 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 19 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 19 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 19 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 19 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 20 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 20 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 20 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 21 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 21 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 21 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 21 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 22 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 22 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 22 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 23 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 23 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 23 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 23 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 24 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 24 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 24 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 25 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 25 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 25 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 25 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 26 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 26 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 26 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 27 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 27 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 27 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 27 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 28 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 28 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 28 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 29 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 29 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 29 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 29 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 30 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 30 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 30 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 31 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 31 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 31 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 31 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 32 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 32 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 32 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 33 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 33 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 33 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 33 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 34 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 34 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 34 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 35 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 35 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 35 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 35 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 36 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 36 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 36 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 37 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 37 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 37 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 37 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 38 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 38 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 38 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 39 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 39 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 39 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 39 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 40 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 40 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 40 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 41 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 41 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 41 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 41 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 42 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 42 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 42 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 43 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 43 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 43 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 43 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 44 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 44 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 44 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 45 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 45 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 45 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 45 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 46 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 46 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 46 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 47 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 47 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 47 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 47 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 48 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 48 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 48 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 49 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 49 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 49 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 49 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 50 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 50 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 50 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 51 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 51 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 51 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 51 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 52 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 52 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 52 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 53 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 53 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 53 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 53 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 54 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 54 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 54 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 55 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 55 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 55 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 55 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 56 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 56 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 56 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 57 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 57 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 57 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 57 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 58 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 58 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 58 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 59 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 59 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 59 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 59 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 60 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 60 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 60 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 61 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 61 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 61 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 61 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 62 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 62 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 62 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 63 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 63 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 63 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 63 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 64 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 64 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 64 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 65 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 65 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 65 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 65 after optimizer step: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 66 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 66 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 66 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 67 start: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 67 after forward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 67 after backward pass: 0.42 GB\n",
      "GPU memory at Epoch 0, Batch 67 after optimizer step: 0.42 GB\n",
      "Max GPU memory allocated: 1.07 GB\n",
      "GPU memory at Before validation: 0.42 GB\n",
      "GPU memory at Validation, Batch 0 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 0 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 1 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 1 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 2 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 2 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 3 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 3 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 4 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 4 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 5 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 5 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 6 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 6 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 7 start: 0.42 GB\n",
      "GPU memory at Validation, Batch 7 end: 0.42 GB\n",
      "GPU memory at Validation, Batch 8 start: 0.42 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-07-24 17:45:13 214234:214234 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-07-24 17:45:13 214234:214234 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.26 GiB. GPU ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m finetuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mfinetune_scFoundation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_downsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_df_downsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFinetunePatientClassification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/models.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m   \n",
      "Cell \u001b[0;32mIn[10], line 108\u001b[0m, in \u001b[0;36mfinetune_scFoundation\u001b[0;34m(gene_expression_csv, labels_df, model_class, ckpt_path, batch_size, num_epochs, lr, validation_split, device, gradient_accumulation_steps)\u001b[0m\n\u001b[1;32m    106\u001b[0m print_gpu_memory(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation, Batch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mj\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    107\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m--> 108\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    109\u001b[0m val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mcompute_loss(logits, batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfloat())\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    110\u001b[0m predicted \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(logits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/scFoundation/scFoundation/model/FinetunePatientClassification.py:64\u001b[0m, in \u001b[0;36mFinetunePatientClassification.forward\u001b[0;34m(self, sample_list, *arg, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m position_emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpos_emb(position_gene_ids)\n\u001b[1;32m     61\u001b[0m x \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_emb \u001b[38;5;66;03m# add the position embedding to token embedding\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_padding\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# pass the encoded data through the encoder\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# mlp\u001b[39;00m\n\u001b[1;32m     67\u001b[0m logits, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(logits, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;66;03m# get the maximum value of the logits along the first dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/scFoundation/scFoundation/model/pretrainmodels/transformer.py:39\u001b[0m, in \u001b[0;36mpytorchTransformerModule.forward\u001b[0;34m(self, x, padding_mask)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# x get encodings [B, N, D] , batch_first is True\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_encoder:\n\u001b[0;32m---> 39\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[43mmod\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msrc_key_padding_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_mask\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# , src_mask=mask, src_key_padding_mask=src_key_padding_mask)\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;66;03m# x = self.transformer_encoder(x)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/modules/transformer.py:720\u001b[0m, in \u001b[0;36mTransformerEncoderLayer.forward\u001b[0;34m(self, src, src_mask, src_key_padding_mask, is_causal)\u001b[0m\n\u001b[1;32m    718\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m why_not_sparsity_fast_path:\n\u001b[1;32m    719\u001b[0m         merged_mask, mask_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn\u001b[38;5;241m.\u001b[39mmerge_masks(src_mask, src_key_padding_mask, src)\n\u001b[0;32m--> 720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer_encoder_layer_fwd\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m            \u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_dim\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    723\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    724\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    725\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43min_proj_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    726\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    727\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout_proj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    728\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactivation_relu_or_gelu\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    729\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_first\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    730\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    732\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    733\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    734\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    735\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    736\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    737\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    738\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    739\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmerged_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    740\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmask_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    741\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    744\u001b[0m x \u001b[38;5;241m=\u001b[39m src\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_first:\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.26 GiB. GPU "
     ]
    }
   ],
   "source": [
    "finetuned_model = finetune_scFoundation(data_downsampled, labels_df_downsampled, model_class=FinetunePatientClassification, \n",
    "                                        ckpt_path='./models/models.ckpt', num_epochs=1, lr=0.001, device='cuda',\n",
    "                                        validation_split=0.2, batch_size=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total GPU Memory: 23.61 GB\n",
      "Available GPU Memory: 22.99 GB\n",
      "Estimated Model Size: 0.00 GB\n",
      "Model size is within available GPU memory.\n",
      "Estimated total memory need (including activations and gradients): 0.00 GB\n",
      "Estimated total memory need is within available GPU memory.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "\n",
    "def get_gpu_memory():\n",
    "    \"\"\"Returns total and available GPU memory in gigabytes\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "        reserved_memory = torch.cuda.memory_reserved(0) / 1e9\n",
    "        allocated_memory = torch.cuda.memory_allocated(0) / 1e9\n",
    "        available_memory = total_memory - (reserved_memory + allocated_memory)\n",
    "        return total_memory, available_memory\n",
    "    else:\n",
    "        return 0, 0\n",
    "\n",
    "def get_model_size(model):\n",
    "    \"\"\"Returns the size of the model in gigabytes\"\"\"\n",
    "    param_size = 0\n",
    "    for param in model.parameters():\n",
    "        param_size += param.nelement() * param.element_size()\n",
    "    buffer_size = 0\n",
    "    for buffer in model.buffers():\n",
    "        buffer_size += buffer.nelement() * buffer.element_size()\n",
    "    size_all_gb = (param_size + buffer_size) / 1024**3\n",
    "    return size_all_gb\n",
    "\n",
    "def check_model_fit(model):\n",
    "    # Clear GPU cache\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    total_memory, available_memory = get_gpu_memory()\n",
    "    model_size = get_model_size(model)\n",
    "\n",
    "    print(f\"Total GPU Memory: {total_memory:.2f} GB\")\n",
    "    print(f\"Available GPU Memory: {available_memory:.2f} GB\")\n",
    "    print(f\"Estimated Model Size: {model_size:.2f} GB\")\n",
    "\n",
    "    if model_size > available_memory:\n",
    "        print(\"WARNING: Model size exceeds available GPU memory!\")\n",
    "    else:\n",
    "        print(\"Model size is within available GPU memory.\")\n",
    "\n",
    "    # Consider memory needed for activations, gradients, and optimizer states\n",
    "    estimated_total_need = model_size * 3  # A rough estimate\n",
    "    print(f\"Estimated total memory need (including activations and gradients): {estimated_total_need:.2f} GB\")\n",
    "\n",
    "    if estimated_total_need > available_memory:\n",
    "        print(\"WARNING: Estimated total memory need exceeds available GPU memory!\")\n",
    "    else:\n",
    "        print(\"Estimated total memory need is within available GPU memory.\")\n",
    "\n",
    "# Usage\n",
    "model = FinetunePatientClassification(ckpt_path='./models/models.ckpt')  # Initialize your model\n",
    "check_model_fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n",
      "self.encoder.transformer_encoder  0.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  0.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  0.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  0.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  0.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  0.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  0.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  0.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  0.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  1.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  1.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  1.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  1.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  1.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  1.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  1.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  1.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  2.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  2.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  2.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  2.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  2.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  2.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  2.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  2.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  3.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  3.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  3.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  3.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  3.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  3.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  3.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  3.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  4.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  4.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  4.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  4.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  4.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  4.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  4.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  4.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  5.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  5.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  5.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  5.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  5.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  5.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  5.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  5.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  6.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  6.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  6.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  6.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  6.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  6.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  6.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  6.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  7.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  7.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  7.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  7.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  7.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  7.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  7.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  7.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  8.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  8.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  8.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  8.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  8.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  8.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  8.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  8.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  9.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  9.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  9.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  9.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  9.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  9.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  9.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  9.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  10.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  10.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  10.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  10.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  10.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  10.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  10.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  10.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  11.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  11.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  11.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  11.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  11.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  11.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  11.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  11.norm2.bias  no grad\n",
      "self.fc1  0.weight  have grad\n",
      "self.fc1  0.bias  have grad\n",
      "self.fc1  2.weight  have grad\n",
      "self.fc1  2.bias  have grad\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'model_state_dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m finetuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mfinetune_scFoundation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_downsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_df_downsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFinetunePatientClassification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/models.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mload_checkpoint_or_not\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8\u001b[39;49m\u001b[43m)\u001b[49m   \n",
      "Cell \u001b[0;32mIn[22], line 38\u001b[0m, in \u001b[0;36mfinetune_scFoundation\u001b[0;34m(gene_expression_csv, labels_df, model_class, ckpt_path, batch_size, num_epochs, lr, validation_split, device, gradient_accumulation_steps, load_checkpoint_or_not)\u001b[0m\n\u001b[1;32m     36\u001b[0m start_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m load_checkpoint_or_not:\n\u001b[0;32m---> 38\u001b[0m     model, optimizer, start_epoch \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(start_epoch, num_epochs):\n\u001b[1;32m     41\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n",
      "Cell \u001b[0;32mIn[21], line 8\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(filename, model, optimizer)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_checkpoint\u001b[39m(filename, model, optimizer):\n\u001b[1;32m      7\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(filename)\n\u001b[0;32m----> 8\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      9\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     10\u001b[0m     epoch \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mKeyError\u001b[0m: 'model_state_dict'"
     ]
    }
   ],
   "source": [
    "finetuned_model = finetune_scFoundation(data_downsampled, labels_df_downsampled, model_class=FinetunePatientClassification, \n",
    "                                        ckpt_path='./models/models.ckpt', num_epochs=5, lr=0.001, device='cuda',\n",
    "                                        validation_split=0.2, load_checkpoint_or_not=True, batch_size=8)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_finetuned_model(model, save_path, model_name):\n",
    "    \"\"\"\n",
    "    Save the finetuned model using both methods: entire model and state dict.\n",
    "    \n",
    "    Args:\n",
    "    model (torch.nn.Module): The finetuned model to save\n",
    "    save_path (str): Directory to save the model\n",
    "    model_name (str): Name to use for the saved model files\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # 1. Save the entire model\n",
    "    entire_model_path = os.path.join(save_path, f\"{model_name}_entire.pth\")\n",
    "    torch.save(model, entire_model_path)\n",
    "    print(f\"Entire model saved to {entire_model_path}\")\n",
    "    \n",
    "    # 2. Save only the state dict\n",
    "    state_dict_path = os.path.join(save_path, f\"{model_name}_state_dict.pth\")\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    print(f\"Model state dict saved to {state_dict_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './saved_models'\n",
    "model_name = 'finetuned_scFoundation'\n",
    "save_finetuned_model(finetuned_model, save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "torch.unsqueeze(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the entire model\n",
    "entire_model_path = os.path.join(save_path, f\"{model_name}_entire.pth\")\n",
    "torch.save(model, entire_model_path)\n",
    "print(f\"Entire model saved to {entire_model_path}\")\n",
    "\n",
    "# 2. Save only the state dict\n",
    "state_dict_path = os.path.join(save_path, f\"{model_name}_state_dict.pth\")\n",
    "torch.save(model.state_dict(), state_dict_path)\n",
    "print(f\"Model state dict saved to {state_dict_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scFoundation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
