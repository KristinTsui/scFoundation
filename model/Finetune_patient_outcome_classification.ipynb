{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import torch\n",
    "from torch import optim\n",
    "from FinetunePatientClassification import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem: bench kept crashing during the train and validation loop. According to torch profiler, the training loop ran but crashed somewhere during validation. There is a sudden spike in GPU usage then the error message appeared. \n",
    "Troubleshooting attempts:\n",
    "x tried downsampling data\n",
    "x batch size\n",
    "x add gradient accumulation\n",
    "x mixed precision training\n",
    "x freeze model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the preprocessed data for scFoundation\n",
    "data = pd.read_csv('gene_symbol_converted_data_for_scF.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsample the data due to GPU limitations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response_3m\n",
       "1    13160\n",
       "0    11906\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.read_csv('patient_metadata.csv')\n",
    "labels_df[\"Response_3m\"].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "patients = labels_df.patient_id.unique()\n",
    "\n",
    "sample_size = 3 # number of patients to sample\n",
    "\n",
    "# randomly sample patient IDs\n",
    "random_seed=42\n",
    "sampled_patient_ids = random.sample(list(patients), sample_size)\n",
    "\n",
    "# Create a new DF with only the sampled patients\n",
    "labels_df_downsampled = labels_df[labels_df['patient_id'].isin(sampled_patient_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample the expression data accordingly\n",
    "data_downsampled = data.iloc[labels_df_downsampled.index]\n",
    "\n",
    "# remove the cell_id column\n",
    "data_downsampled = data_downsampled.drop(columns=['cell_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1345, 19264), (1345, 7))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make sure the data and labels are aligned\n",
    "data_downsampled.shape, labels_df_downsampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A1BG</th>\n",
       "      <th>A1CF</th>\n",
       "      <th>A2M</th>\n",
       "      <th>A2ML1</th>\n",
       "      <th>A3GALT2</th>\n",
       "      <th>A4GALT</th>\n",
       "      <th>A4GNT</th>\n",
       "      <th>AAAS</th>\n",
       "      <th>AACS</th>\n",
       "      <th>AADAC</th>\n",
       "      <th>...</th>\n",
       "      <th>ZWILCH</th>\n",
       "      <th>ZWINT</th>\n",
       "      <th>ZXDA</th>\n",
       "      <th>ZXDB</th>\n",
       "      <th>ZXDC</th>\n",
       "      <th>ZYG11A</th>\n",
       "      <th>ZYG11B</th>\n",
       "      <th>ZYX</th>\n",
       "      <th>ZZEF1</th>\n",
       "      <th>ZZZ3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>891</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>892</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>893</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20301</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20302</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20303</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20304</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20305</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2872 rows × 19264 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       A1BG  A1CF  A2M  A2ML1  A3GALT2  A4GALT  A4GNT  AAAS  AACS  AADAC  ...  \\\n",
       "889     0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "890     0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "891     0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "892     0.0   0.0  0.0    0.0      0.0     0.0    0.0   1.0   0.0    0.0  ...   \n",
       "893     0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "...     ...   ...  ...    ...      ...     ...    ...   ...   ...    ...  ...   \n",
       "20301   0.0   0.0  0.0    0.0      0.0     0.0    0.0   1.0   0.0    0.0  ...   \n",
       "20302   0.0   0.0  0.0    0.0      0.0     0.0    0.0   1.0   0.0    0.0  ...   \n",
       "20303   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "20304   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   0.0    0.0  ...   \n",
       "20305   0.0   0.0  0.0    0.0      0.0     0.0    0.0   0.0   1.0    0.0  ...   \n",
       "\n",
       "       ZWILCH  ZWINT  ZXDA  ZXDB  ZXDC  ZYG11A  ZYG11B  ZYX  ZZEF1  ZZZ3  \n",
       "889       0.0    0.0   0.0   0.0   0.0     0.0     0.0  2.0    0.0   0.0  \n",
       "890       0.0    0.0   0.0   0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "891       0.0    0.0   0.0   0.0   0.0     0.0     0.0  4.0    0.0   0.0  \n",
       "892       0.0    0.0   0.0   0.0   0.0     0.0     0.0  3.0    0.0   0.0  \n",
       "893       0.0    0.0   0.0   0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "...       ...    ...   ...   ...   ...     ...     ...  ...    ...   ...  \n",
       "20301     0.0    0.0   0.0   0.0   0.0     0.0     0.0  2.0    0.0   0.0  \n",
       "20302     0.0    0.0   0.0   0.0   0.0     0.0     0.0  3.0    0.0   0.0  \n",
       "20303     0.0    0.0   0.0   0.0   0.0     0.0     0.0  0.0    0.0   0.0  \n",
       "20304     0.0    0.0   0.0   0.0   0.0     0.0     0.0  4.0    0.0   0.0  \n",
       "20305     0.0    0.0   0.0   0.0   0.0     0.0     0.0  2.0    0.0   0.0  \n",
       "\n",
       "[2872 rows x 19264 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_downsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetune the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SingleCellDataset(Dataset):\n",
    "    def __init__(self, gene_expression_csv, labels_df, label_encoder):\n",
    "        # Load the gene expression data\n",
    "        self.gene_expression = gene_expression_csv\n",
    "        \n",
    "        # Ensure the labels DataFrame has the same number of rows as the gene expression data\n",
    "        assert len(self.gene_expression) == len(labels_df), \"Mismatch in number of samples between gene expression data and labels\"\n",
    "        \n",
    "        # Convert labels to numeric if they're categorical\n",
    "        \n",
    "        self.labels = torch.LongTensor(label_encoder.transform(labels_df['Response_3m']))\n",
    "        \n",
    "        \n",
    "        # Convert gene expression data to torch tensor\n",
    "        self.gene_expression = torch.FloatTensor(self.gene_expression.values.astype(np.float32))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'x': self.gene_expression[idx],\n",
    "            'targets': self.labels[idx]\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "\n",
    "def print_gpu_memory(step_name):\n",
    "    print(f\"GPU memory at {step_name}: {torch.cuda.memory_allocated() / 1e9:.2f} GB\")\n",
    "\n",
    "def finetune_scFoundation(gene_expression_csv, labels_df, model_class, ckpt_path,\n",
    "                          batch_size=4, num_epochs=5, lr=0.001,\n",
    "                          validation_split=0.2, device='cuda',\n",
    "                          gradient_accumulation_steps=2):\n",
    "    \n",
    "    gene_exp_train, gene_exp_val, labels_train, labels_val = train_test_split(gene_expression_csv, \n",
    "                                                                              labels_df, test_size=validation_split, \n",
    "                                                                              random_state=42)\n",
    "\n",
    "    # Fit LabelEncoder on combined dataset\n",
    "    le = LabelEncoder()\n",
    "    combined_labels = pd.concat([labels_train['Response_3m'], labels_val['Response_3m']])\n",
    "    le.fit(combined_labels)\n",
    "\n",
    "    #create datasets\n",
    "    train_dataset = SingleCellDataset(gene_exp_train, labels_train, le)\n",
    "    val_dataset = SingleCellDataset(gene_exp_val, labels_val, le)\n",
    "\n",
    "    #create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size = batch_size // 2, shuffle=False, num_workers=4, pin_memory=True)  # Ensure at least 2, but no more than 8\n",
    "\n",
    "    # Initialize model\n",
    "    model = model_class(ckpt_path=ckpt_path)\n",
    "    model.build()\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Initialize optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    # Initialize gradient scaler for mixed precision training\n",
    "    scaler = GradScaler()\n",
    "\n",
    "    # Optionally load checkpoint\n",
    "    start_epoch = 0\n",
    "    \n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
    "            profile_memory=True, record_shapes=True) as prof:\n",
    "        \n",
    "        best_val_loss = float('inf')\n",
    "        patience = 10\n",
    "        patience_counter = 0\n",
    "\n",
    "        for epoch in range(start_epoch, num_epochs):\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "\n",
    "            # Clear CUDA cache\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "            for i, batch in enumerate(train_loader):\n",
    "                print_gpu_memory(f\"Epoch {epoch}, Batch {i} start\")\n",
    "                # Move batch to device\n",
    "                batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "                # Mixed precision training\n",
    "                with autocast():\n",
    "                    # Forward pass\n",
    "                    logits = model(batch)\n",
    "\n",
    "                    # Compute loss\n",
    "                    loss = model.compute_loss(logits, batch['targets'].float()) / gradient_accumulation_steps\n",
    "                \n",
    "                print_gpu_memory(f\"Epoch {epoch}, Batch {i} after forward pass\")\n",
    "                # Ensure loss requires gradient\n",
    "                assert loss.requires_grad, \"Loss does not require gradients\"\n",
    "\n",
    "                # Backward pass with gradient scaling\n",
    "                scaler.scale(loss).backward()\n",
    "\n",
    "                print_gpu_memory(f\"Epoch {epoch}, Batch {i} after backward pass\")\n",
    "\n",
    "                if (i + 1) % gradient_accumulation_steps == 0:\n",
    "                    # Unscale gradients and optimizer step\n",
    "                    scaler.unscale_(optimizer)\n",
    "                    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # add garbage collection\n",
    "                    gc.collect()\n",
    "                    torch.cuda.empty_cache()\n",
    "                \n",
    "                    print_gpu_memory(f\"Epoch {epoch}, Batch {i} after optimizer step\")\n",
    "\n",
    "                train_loss += loss.item() * gradient_accumulation_steps\n",
    "            print(f\"Max GPU memory allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "    \n",
    "\n",
    "\n",
    "            #validation\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            correct = 0\n",
    "            total = 0\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "            print_gpu_memory(f\"Before validation\")\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for j, batch in enumerate(val_loader):\n",
    "                    print_gpu_memory(f\"Validation, Batch {j} start\")\n",
    "                    if batch['input'].size(0) < 2:  # Skip batches smaller than 2\n",
    "                        continue\n",
    "                    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "                    logits = model(batch)\n",
    "                    val_loss += model.compute_loss(logits, batch['targets'].float()).item()\n",
    "                    predicted = (torch.sigmoid(logits) > 0.5).float()\n",
    "                    total += batch['targets'].size(0)\n",
    "                    correct += (predicted == batch['targets']).sum().item()\n",
    "\n",
    "                    # Move data back to CPU\n",
    "                    for k in batch.keys():\n",
    "                        batch[k] = batch[k].cpu()\n",
    "                    del batch, logits, predicted\n",
    "                    torch.cuda.empty_cache()\n",
    "\n",
    "                    print_gpu_memory(f\"Validation, Batch {j} end\")\n",
    "\n",
    "                    \n",
    "            \n",
    "            # Print epoch results\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Train Loss: {train_loss/len(train_loader):.4f}\")\n",
    "            print(f\"Validation Loss: {val_loss/len(val_loader):.4f}\")\n",
    "            print(f\"Validation Accuracy: {100*correct/total:.2f}%\")\n",
    "            print(\"-----------------------------\")\n",
    "    \n",
    "    \n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n",
    "    print(f\"Peak CUDA memory allocated: {torch.cuda.max_memory_allocated() / 1e9:.2f} GB\")\n",
    "    print(f\"Peak CUDA memory reserved: {torch.cuda.max_memory_reserved() / 1e9:.2f} GB\")\n",
    "    print(\"\\nCUDA Memory Summary:\")\n",
    "    print(torch.cuda.memory_summary())\n",
    "\n",
    "    return model\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mask_gene_name': False, 'gene_num': 19266, 'seq_len': 19266, 'encoder': {'hidden_dim': 768, 'depth': 12, 'heads': 12, 'dim_head': 64, 'seq_len': 19266, 'module_type': 'transformer', 'norm_first': False}, 'decoder': {'hidden_dim': 512, 'depth': 6, 'heads': 8, 'dim_head': 64, 'module_type': 'performer', 'seq_len': 19266, 'norm_first': False}, 'n_class': 104, 'pad_token_id': 103, 'mask_token_id': 102, 'bin_num': 100, 'bin_alpha': 1.0, 'rawcount': True, 'model': 'mae_autobin', 'test_valid_train_idx_dict': '/nfs_beijing/minsheng/data/os10000w-new/global_shuffle/meta.csv.train_set_idx_dict.pt', 'valid_data_path': '/nfs_beijing/minsheng/data/valid_count_10w.npz', 'num_tokens': 13, 'train_data_path': None, 'isPanA': False, 'isPlanA1': False, 'max_files_to_load': 5, 'bin_type': 'auto_bin', 'value_mask_prob': 0.3, 'zero_mask_prob': 0.03, 'replace_prob': 0.8, 'random_token_prob': 0.1, 'mask_ignore_token_ids': [0], 'decoder_add_zero': True, 'mae_encoder_max_seq_len': 15000, 'isPlanA': False, 'mask_prob': 0.3, 'model_type': 'mae_autobin', 'pos_embed': False, 'device': 'cuda'}\n",
      "self.encoder.transformer_encoder  0.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  0.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  0.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  0.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  0.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  0.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  0.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  0.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  0.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  0.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  1.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  1.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  1.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  1.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  1.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  1.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  1.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  1.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  1.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  2.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  2.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  2.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  2.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  2.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  2.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  2.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  2.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  2.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  3.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  3.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  3.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  3.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  3.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  3.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  3.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  3.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  3.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  4.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  4.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  4.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  4.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  4.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  4.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  4.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  4.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  4.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  5.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  5.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  5.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  5.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  5.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  5.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  5.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  5.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  5.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  6.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  6.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  6.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  6.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  6.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  6.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  6.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  6.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  6.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  7.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  7.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  7.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  7.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  7.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  7.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  7.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  7.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  7.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  8.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  8.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  8.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  8.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  8.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  8.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  8.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  8.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  8.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  9.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  9.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  9.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  9.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  9.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  9.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  9.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  9.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  9.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  10.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  10.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  10.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  10.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  10.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  10.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  10.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  10.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  10.norm2.bias  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.in_proj_weight  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.in_proj_bias  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.out_proj.weight  no grad\n",
      "self.encoder.transformer_encoder  11.self_attn.out_proj.bias  no grad\n",
      "self.encoder.transformer_encoder  11.linear1.weight  no grad\n",
      "self.encoder.transformer_encoder  11.linear1.bias  no grad\n",
      "self.encoder.transformer_encoder  11.linear2.weight  no grad\n",
      "self.encoder.transformer_encoder  11.linear2.bias  no grad\n",
      "self.encoder.transformer_encoder  11.norm1.weight  no grad\n",
      "self.encoder.transformer_encoder  11.norm1.bias  no grad\n",
      "self.encoder.transformer_encoder  11.norm2.weight  no grad\n",
      "self.encoder.transformer_encoder  11.norm2.bias  no grad\n",
      "self.fc1  0.weight  have grad\n",
      "self.fc1  0.bias  have grad\n",
      "self.fc1  2.weight  have grad\n",
      "self.fc1  2.bias  have grad\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-07-26 01:16:38 71250:71250 ActivityProfilerController.cpp:314] Completed Stage: Warm Up\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory at Epoch 0, Batch 0 start: 1.43 GB\n",
      "GPU memory at Epoch 0, Batch 0 after forward pass: 1.43 GB\n",
      "GPU memory at Epoch 0, Batch 0 after backward pass: 1.43 GB\n",
      "GPU memory at Epoch 0, Batch 1 start: 1.43 GB\n",
      "GPU memory at Epoch 0, Batch 1 after forward pass: 1.43 GB\n",
      "GPU memory at Epoch 0, Batch 1 after backward pass: 1.43 GB\n",
      "GPU memory at Epoch 0, Batch 1 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 2 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 2 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 2 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 3 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 3 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 3 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 3 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 4 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 4 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 4 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 5 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 5 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 5 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 5 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 6 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 6 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 6 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 7 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 7 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 7 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 7 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 8 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 8 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 8 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 9 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 9 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 9 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 9 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 10 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 10 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 10 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 11 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 11 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 11 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 11 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 12 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 12 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 12 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 13 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 13 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 13 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 13 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 14 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 14 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 14 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 15 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 15 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 15 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 15 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 16 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 16 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 16 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 17 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 17 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 17 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 17 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 18 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 18 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 18 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 19 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 19 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 19 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 19 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 20 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 20 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 20 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 21 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 21 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 21 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 21 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 22 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 22 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 22 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 23 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 23 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 23 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 23 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 24 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 24 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 24 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 25 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 25 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 25 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 25 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 26 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 26 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 26 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 27 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 27 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 27 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 27 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 28 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 28 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 28 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 29 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 29 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 29 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 29 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 30 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 30 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 30 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 31 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 31 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 31 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 31 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 32 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 32 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 32 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 33 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 33 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 33 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 33 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 34 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 34 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 34 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 35 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 35 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 35 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 35 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 36 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 36 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 36 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 37 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 37 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 37 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 37 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 38 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 38 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 38 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 39 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 39 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 39 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 39 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 40 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 40 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 40 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 41 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 41 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 41 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 41 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 42 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 42 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 42 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 43 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 43 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 43 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 43 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 44 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 44 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 44 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 45 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 45 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 45 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 45 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 46 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 46 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 46 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 47 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 47 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 47 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 47 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 48 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 48 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 48 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 49 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 49 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 49 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 49 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 50 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 50 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 50 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 51 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 51 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 51 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 51 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 52 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 52 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 52 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 53 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 53 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 53 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 53 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 54 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 54 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 54 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 55 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 55 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 55 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 55 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 56 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 56 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 56 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 57 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 57 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 57 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 57 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 58 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 58 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 58 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 59 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 59 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 59 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 59 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 60 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 60 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 60 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 61 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 61 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 61 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 61 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 62 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 62 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 62 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 63 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 63 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 63 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 63 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 64 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 64 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 64 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 65 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 65 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 65 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 65 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 66 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 66 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 66 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 67 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 67 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 67 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 67 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 68 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 68 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 68 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 69 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 69 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 69 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 69 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 70 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 70 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 70 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 71 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 71 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 71 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 71 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 72 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 72 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 72 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 73 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 73 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 73 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 73 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 74 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 74 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 74 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 75 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 75 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 75 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 75 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 76 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 76 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 76 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 77 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 77 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 77 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 77 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 78 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 78 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 78 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 79 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 79 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 79 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 79 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 80 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 80 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 80 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 81 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 81 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 81 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 81 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 82 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 82 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 82 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 83 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 83 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 83 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 83 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 84 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 84 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 84 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 85 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 85 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 85 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 85 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 86 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 86 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 86 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 87 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 87 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 87 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 87 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 88 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 88 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 88 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 89 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 89 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 89 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 89 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 90 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 90 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 90 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 91 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 91 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 91 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 91 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 92 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 92 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 92 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 93 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 93 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 93 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 93 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 94 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 94 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 94 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 95 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 95 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 95 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 95 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 96 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 96 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 96 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 97 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 97 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 97 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 97 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 98 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 98 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 98 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 99 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 99 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 99 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 99 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 100 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 100 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 100 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 101 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 101 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 101 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 101 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 102 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 102 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 102 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 103 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 103 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 103 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 103 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 104 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 104 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 104 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 105 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 105 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 105 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 105 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 106 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 106 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 106 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 107 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 107 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 107 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 107 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 108 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 108 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 108 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 109 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 109 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 109 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 109 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 110 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 110 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 110 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 111 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 111 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 111 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 111 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 112 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 112 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 112 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 113 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 113 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 113 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 113 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 114 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 114 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 114 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 115 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 115 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 115 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 115 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 116 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 116 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 116 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 117 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 117 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 117 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 117 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 118 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 118 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 118 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 119 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 119 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 119 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 119 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 120 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 120 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 120 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 121 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 121 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 121 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 121 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 122 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 122 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 122 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 123 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 123 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 123 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 123 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 124 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 124 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 124 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 125 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 125 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 125 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 125 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 126 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 126 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 126 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 127 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 127 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 127 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 127 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 128 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 128 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 128 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 129 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 129 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 129 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 129 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 130 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 130 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 130 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 131 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 131 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 131 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 131 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 132 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 132 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 132 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 133 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 133 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 133 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 133 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 134 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 134 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 134 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 135 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 135 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 135 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 135 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 136 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 136 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 136 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 137 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 137 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 137 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 137 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 138 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 138 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 138 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 139 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 139 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 139 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 139 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 140 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 140 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 140 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 141 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 141 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 141 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 141 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 142 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 142 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 142 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 143 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 143 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 143 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 143 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 144 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 144 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 144 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 145 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 145 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 145 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 145 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 146 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 146 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 146 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 147 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 147 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 147 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 147 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 148 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 148 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 148 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 149 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 149 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 149 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 149 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 150 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 150 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 150 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 151 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 151 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 151 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 151 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 152 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 152 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 152 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 153 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 153 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 153 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 153 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 154 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 154 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 154 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 155 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 155 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 155 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 155 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 156 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 156 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 156 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 157 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 157 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 157 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 157 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 158 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 158 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 158 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 159 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 159 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 159 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 159 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 160 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 160 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 160 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 161 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 161 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 161 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 161 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 162 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 162 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 162 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 163 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 163 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 163 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 163 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 164 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 164 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 164 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 165 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 165 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 165 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 165 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 166 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 166 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 166 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 167 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 167 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 167 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 167 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 168 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 168 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 168 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 169 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 169 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 169 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 169 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 170 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 170 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 170 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 171 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 171 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 171 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 171 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 172 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 172 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 172 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 173 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 173 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 173 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 173 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 174 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 174 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 174 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 175 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 175 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 175 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 175 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 176 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 176 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 176 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 177 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 177 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 177 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 177 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 178 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 178 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 178 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 179 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 179 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 179 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 179 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 180 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 180 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 180 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 181 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 181 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 181 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 181 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 182 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 182 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 182 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 183 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 183 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 183 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 183 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 184 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 184 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 184 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 185 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 185 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 185 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 185 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 186 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 186 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 186 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 187 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 187 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 187 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 187 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 188 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 188 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 188 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 189 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 189 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 189 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 189 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 190 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 190 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 190 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 191 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 191 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 191 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 191 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 192 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 192 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 192 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 193 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 193 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 193 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 193 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 194 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 194 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 194 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 195 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 195 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 195 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 195 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 196 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 196 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 196 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 197 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 197 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 197 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 197 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 198 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 198 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 198 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 199 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 199 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 199 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 199 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 200 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 200 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 200 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 201 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 201 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 201 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 201 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 202 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 202 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 202 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 203 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 203 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 203 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 203 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 204 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 204 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 204 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 205 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 205 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 205 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 205 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 206 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 206 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 206 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 207 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 207 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 207 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 207 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 208 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 208 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 208 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 209 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 209 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 209 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 209 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 210 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 210 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 210 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 211 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 211 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 211 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 211 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 212 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 212 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 212 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 213 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 213 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 213 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 213 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 214 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 214 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 214 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 215 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 215 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 215 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 215 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 216 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 216 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 216 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 217 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 217 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 217 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 217 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 218 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 218 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 218 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 219 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 219 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 219 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 219 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 220 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 220 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 220 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 221 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 221 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 221 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 221 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 222 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 222 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 222 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 223 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 223 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 223 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 223 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 224 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 224 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 224 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 225 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 225 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 225 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 225 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 226 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 226 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 226 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 227 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 227 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 227 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 227 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 228 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 228 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 228 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 229 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 229 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 229 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 229 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 230 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 230 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 230 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 231 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 231 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 231 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 231 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 232 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 232 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 232 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 233 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 233 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 233 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 233 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 234 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 234 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 234 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 235 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 235 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 235 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 235 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 236 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 236 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 236 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 237 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 237 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 237 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 237 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 238 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 238 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 238 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 239 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 239 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 239 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 239 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 240 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 240 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 240 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 241 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 241 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 241 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 241 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 242 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 242 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 242 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 243 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 243 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 243 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 243 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 244 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 244 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 244 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 245 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 245 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 245 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 245 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 246 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 246 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 246 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 247 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 247 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 247 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 247 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 248 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 248 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 248 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 249 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 249 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 249 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 249 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 250 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 250 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 250 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 251 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 251 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 251 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 251 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 252 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 252 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 252 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 253 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 253 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 253 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 253 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 254 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 254 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 254 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 255 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 255 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 255 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 255 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 256 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 256 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 256 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 257 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 257 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 257 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 257 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 258 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 258 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 258 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 259 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 259 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 259 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 259 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 260 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 260 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 260 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 261 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 261 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 261 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 261 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 262 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 262 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 262 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 263 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 263 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 263 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 263 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 264 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 264 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 264 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 265 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 265 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 265 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 265 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 266 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 266 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 266 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 267 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 267 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 267 after backward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 267 after optimizer step: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 268 start: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 268 after forward pass: 1.02 GB\n",
      "GPU memory at Epoch 0, Batch 268 after backward pass: 1.02 GB\n",
      "Max GPU memory allocated: 19.14 GB\n",
      "GPU memory at Before validation: 1.02 GB\n",
      "GPU memory at Validation, Batch 0 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 0 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 1 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 1 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 2 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 2 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 3 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 3 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 4 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 4 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 5 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 5 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 6 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 6 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 7 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 7 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 8 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 8 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 9 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 9 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 10 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 10 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 11 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 11 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 12 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 12 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 13 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 13 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 14 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 14 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 15 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 15 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 16 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 16 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 17 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 17 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 18 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 18 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 19 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 19 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 20 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 20 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 21 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 21 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 22 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 22 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 23 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 23 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 24 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 24 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 25 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 25 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 26 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 26 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 27 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 27 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 28 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 28 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 29 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 29 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 30 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 30 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 31 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 31 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 32 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 32 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 33 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 33 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 34 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 34 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 35 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 35 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 36 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 36 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 37 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 37 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 38 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 38 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 39 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 39 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 40 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 40 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 41 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 41 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 42 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 42 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 43 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 43 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 44 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 44 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 45 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 45 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 46 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 46 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 47 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 47 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 48 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 48 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 49 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 49 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 50 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 50 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 51 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 51 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 52 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 52 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 53 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 53 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 54 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 54 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 55 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 55 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 56 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 56 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 57 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 57 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 58 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 58 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 59 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 59 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 60 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 60 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 61 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 61 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 62 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 62 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 63 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 63 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 64 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 64 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 65 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 65 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 66 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 66 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 67 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 67 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 68 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 68 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 69 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 69 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 70 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 70 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 71 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 71 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 72 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 72 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 73 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 73 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 74 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 74 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 75 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 75 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 76 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 76 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 77 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 77 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 78 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 78 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 79 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 79 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 80 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 80 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 81 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 81 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 82 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 82 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 83 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 83 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 84 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 84 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 85 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 85 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 86 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 86 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 87 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 87 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 88 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 88 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 89 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 89 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 90 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 90 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 91 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 91 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 92 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 92 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 93 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 93 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 94 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 94 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 95 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 95 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 96 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 96 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 97 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 97 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 98 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 98 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 99 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 99 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 100 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 100 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 101 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 101 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 102 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 102 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 103 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 103 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 104 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 104 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 105 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 105 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 106 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 106 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 107 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 107 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 108 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 108 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 109 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 109 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 110 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 110 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 111 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 111 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 112 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 112 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 113 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 113 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 114 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 114 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 115 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 115 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 116 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 116 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 117 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 117 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 118 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 118 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 119 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 119 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 120 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 120 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 121 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 121 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 122 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 122 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 123 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 123 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 124 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 124 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 125 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 125 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 126 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 126 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 127 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 127 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 128 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 128 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 129 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 129 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 130 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 130 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 131 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 131 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 132 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 132 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 133 start: 1.02 GB\n",
      "GPU memory at Validation, Batch 133 end: 1.02 GB\n",
      "GPU memory at Validation, Batch 134 start: 1.02 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "STAGE:2024-07-26 01:25:53 71250:71250 ActivityProfilerController.cpp:320] Completed Stage: Collection\n",
      "STAGE:2024-07-26 01:25:53 71250:71250 ActivityProfilerController.cpp:324] Completed Stage: Post Processing\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target size (torch.Size([1])) must be the same as input size (torch.Size([]))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m finetuned_model \u001b[38;5;241m=\u001b[39m \u001b[43mfinetune_scFoundation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_downsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels_df_downsampled\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFinetunePatientClassification\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./models/models.ckpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.001\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m   \n",
      "Cell \u001b[0;32mIn[22], line 113\u001b[0m, in \u001b[0;36mfinetune_scFoundation\u001b[0;34m(gene_expression_csv, labels_df, model_class, ckpt_path, batch_size, num_epochs, lr, validation_split, device, gradient_accumulation_steps)\u001b[0m\n\u001b[1;32m    111\u001b[0m batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mto(device) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    112\u001b[0m logits \u001b[38;5;241m=\u001b[39m model(batch)\n\u001b[0;32m--> 113\u001b[0m val_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtargets\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    114\u001b[0m predicted \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39msigmoid(logits) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    115\u001b[0m total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtargets\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/scFoundation/scFoundation/model/FinetunePatientClassification.py:76\u001b[0m, in \u001b[0;36mFinetunePatientClassification.compute_loss\u001b[0;34m(self, logits, targets)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_loss\u001b[39m(\u001b[38;5;28mself\u001b[39m, logits, targets):\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunctional\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_cross_entropy_with_logits\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlogits\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.apps/conda/envs/scFoundation/lib/python3.9/site-packages/torch/nn/functional.py:3197\u001b[0m, in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     reduction_enum \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction)\n\u001b[1;32m   3196\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (target\u001b[38;5;241m.\u001b[39msize() \u001b[38;5;241m==\u001b[39m \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()):\n\u001b[0;32m-> 3197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) must be the same as input size (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mbinary_cross_entropy_with_logits(\u001b[38;5;28minput\u001b[39m, target, weight, pos_weight, reduction_enum)\n",
      "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([1])) must be the same as input size (torch.Size([]))"
     ]
    }
   ],
   "source": [
    "finetuned_model = finetune_scFoundation(data_downsampled, labels_df_downsampled, model_class=FinetunePatientClassification, \n",
    "                                        ckpt_path='./models/models.ckpt', num_epochs=1, lr=0.001, device='cuda',\n",
    "                                        validation_split=0.2, batch_size=4)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def save_finetuned_model(model, save_path, model_name):\n",
    "    \"\"\"\n",
    "    Save the finetuned model using both methods: entire model and state dict.\n",
    "    \n",
    "    Args:\n",
    "    model (torch.nn.Module): The finetuned model to save\n",
    "    save_path (str): Directory to save the model\n",
    "    model_name (str): Name to use for the saved model files\n",
    "    \"\"\"\n",
    "    # Ensure the save directory exists\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "    \n",
    "    # 1. Save the entire model\n",
    "    entire_model_path = os.path.join(save_path, f\"{model_name}_entire.pth\")\n",
    "    torch.save(model, entire_model_path)\n",
    "    print(f\"Entire model saved to {entire_model_path}\")\n",
    "    \n",
    "    # 2. Save only the state dict\n",
    "    state_dict_path = os.path.join(save_path, f\"{model_name}_state_dict.pth\")\n",
    "    torch.save(model.state_dict(), state_dict_path)\n",
    "    print(f\"Model state dict saved to {state_dict_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = './saved_models'\n",
    "model_name = 'finetuned_scFoundation'\n",
    "save_finetuned_model(finetuned_model, save_path, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1],\n",
       "        [2],\n",
       "        [3],\n",
       "        [4]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3, 4])\n",
    "torch.unsqueeze(x, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Save the entire model\n",
    "entire_model_path = os.path.join(save_path, f\"{model_name}_entire.pth\")\n",
    "torch.save(model, entire_model_path)\n",
    "print(f\"Entire model saved to {entire_model_path}\")\n",
    "\n",
    "# 2. Save only the state dict\n",
    "state_dict_path = os.path.join(save_path, f\"{model_name}_state_dict.pth\")\n",
    "torch.save(model.state_dict(), state_dict_path)\n",
    "print(f\"Model state dict saved to {state_dict_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scFoundation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
